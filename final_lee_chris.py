# -*- coding: utf-8 -*-
"""Final_Lee_Chris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13YQULCCg3A-XUY6LUlYCK8ooYC1_eHKE

## **Machine Learning Final Project DUE: Friday May 7th 11:59pm**

**Note: Please read all the instructions carefully before starting the project.**

For your final project you will build an ML model to analyze a dataset of your choice. You are welcome to keep working on the data in your EDA project if your data is large enough (at least 1000 rows for simple models and at least 10,000 for more complex models) or you can choose from the datasets/project suggestions below.

In this project make sure that you:
- Have a large enough dataset
- Split your data in training and testing
- Explore your data to inform which type of model to choose (no need if you are using your EDA dataset)
- Try different models on your training dataset - then select the most promising model
- Use cross validation to fine tune the model’s parameters such as alpha in lasso
- Simplify your model using regularization, prunnning, drop-out, etc. to avoid overfitting
- Communicate your model’s performance and make sure you compare it to a benchmark when appropriate
- Plot interesting graphs and results
- Write and publish your article to medium
- Commit your code to your GitHub

Please ensure you handle all the preprocessing before the modeling.

Suggestions for project:
You can take a look at the resources given below for choosing a dataset for your project. 

- Traffic sign detection - https://benchmark.ini.rub.de/gtsdb_dataset.html
- Cat and dog classifier - https://www.kaggle.com/c/dogs-vs-cats/data
- Other datasets from Kaggle - https://www.kaggle.com/data/41592

## **Grading Criteria**

- Show clear exploration of the data to justify model choice
- Train mutliple models and clearly articulate why you chose your final model
- Show your performance on test dataset
- Clear and concise write-up with clear well-documented figures
- Commit your code to GitHub

## **Submission Details**

This is an individual assignment. You may not work in groups. The assignment is due on Friday (05/07/2021)
- To submit your assignment, download your notebook and the dataset, zip the dataset and notebook, and submit the zipped file on blackboard.
- Make sure the notebook is named in the format - Final_LastName_FirstName. If you are submitting a zipped file, please name the file as well in the same format.
- Please include the link to access your blog and your github repo in your notebook.
- Also include the link to your notebook, github repo and the blog in the submission on blackboard. Please ensure the TAs have the required access to your notebooks and the github repo.

**Note - If the dataset is too large to be zipped and submitted on blackboard, only submit your notebook, add your dataset to your google drive and share a link to the file in your notebook.**
"""

#imports 

import pandas as pd
import numpy as np
from numpy import asarray
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.dummy import DummyClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.utils import shuffle
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import array_to_img
from keras.utils import to_categorical
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_validate
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.model_selection import RandomizedSearchCV
from matplotlib import pyplot as plt
from zipfile import ZipFile
from zipfile import *
import warnings
import cv2
import os

#import data 
ZipFile("train.zip", "r").extractall()
ZipFile("test1.zip", "r").extractall()
train_dir = "./train/"
test_dir  = "./test1/"

train_names = os.listdir(train_dir)
categories = []

for filename in train_names:
    category = filename.split(".")[0]
    categories.append(category)
df = pd.DataFrame({
    "filename": train_names,
    "category": categories
})

df["category"] = df["category"].replace({0: 'cat', 1: 'dog'})

df.shape

df.describe

df['category'].value_counts().plot.bar()

train_images = [train_dir+i for i in os.listdir(train_dir)]
test_images = [test_dir+i for i in os.listdir(test_dir)]

ROWS = 64
COLS = 64
CHANNELS = 3

def read_image(file_path):
  #print(file_path)
  img = cv2.imread(file_path, cv2.IMREAD_COLOR)
  #print(img)
  return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)

def prep_data(images):
    m = len(images)
    n_x = ROWS*COLS*CHANNELS
    X = np.ndarray((m,ROWS,COLS,CHANNELS), dtype=np.uint8)
    y = np.zeros((m,1))
    print("x.shape = {}".format(X.shape))
    
    for i,image_file in enumerate(images):
        image = read_image(image_file)
        X[i,:] = np.squeeze(image.reshape((ROWS, COLS, CHANNELS)))
        if 'dog' in image_file.lower():
            y[i,0] = 1
        elif 'cat' in image_file.lower():
            y[i,0] = 0
        else : # for test datasp
            y[i,0] = image_file.split('/')[-1].split('.')[0]
            print(image_file.split('/')[-1].split('.')[0])
        if i%5000 == 0 :
            print("{} of {} done".format(i, m))
    return X,y

X_train, y_train = prep_data(train_images)
X_test, y_test = prep_data(test_images)

X_train.shape

X_test.shape

X_train = X_train.reshape(2000,3*64*64)
X_test = X_test.reshape(1000,3*64*64)

X_train.shape

X_test.shape

X, y = shuffle(X_train, y_train)

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

d = DummyClassifier(strategy='most_frequent')
d.fit(X_train, y_train)
d.score(X_test, y_test)

bag_model_1 = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators=10, random_state=42)
bag_model_1 = bag_model_1.fit(X_train, y_train.ravel())
bag_pred_1 = bag_model_1.predict(X_test)
print("Generic Bagging Accuracy: {}".format(accuracy_score(y_test, bag_pred_1)))

bag_model_2 = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators=30, random_state=42)
bag_model_2 = bag_model_2.fit(X_train, y_train.ravel())
bag_pred_2 = bag_model_2.predict(X_test)
print("Generic Bagging Accuracy: {}".format(accuracy_score(y_test, bag_pred_2)))

bag_model_3 = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators=50, random_state=42)
bag_model_3 = bag_model_3.fit(X_train, y_train.ravel())
bag_pred_3 = bag_model_3.predict(X_test)
print("Generic Bagging Accuracy: {}".format(accuracy_score(y_test, bag_pred_3)))

rf_model = RandomForestClassifier(n_estimators=1, max_features=7, random_state=42)

n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]

random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}

rf_model = RandomizedSearchCV(estimator = rf_model, param_distributions = random_grid, n_iter = 1, cv = 3, verbose=2, random_state=42, n_jobs = -1)

rf_model = rf_model.fit(X_train, y_train.ravel())
rf_pred = rf_model.predict(X_test)
print("Random Forest Accuracy: {}".format(accuracy_score(y_test, rf_pred)))

boost_model_1 = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=4), n_estimators=10, random_state=42, learning_rate =0.05)
boost_model_1 = boost_model_1.fit(X_train, y_train.ravel())
boost_pred_1 = boost_model_1.predict(X_test)
print("AdaBoost Classification Accuracy: {}".format(accuracy_score(y_test, boost_pred_1)))

boost_model_2 = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=10), n_estimators=30, random_state=42, learning_rate =0.07)
boost_model_2 = boost_model_2.fit(X_train, y_train.ravel())
boost_pred_2 = boost_model_2.predict(X_test)
boost_accuracy = accuracy_score(y_test, boost_pred_2)
print(boost_accuracy)
print("AdaBoost Classification Accuracy: {}".format(accuracy_score(y_test, boost_pred_2)))

boost_model_3 = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=20), n_estimators=50, random_state=42, learning_rate =0.1)
boost_model_3 = boost_model_3.fit(X_train, y_train.ravel())
boost_pred_3 = boost_model_3.predict(X_test)
print("AdaBoost Classification Accuracy: {}".format(accuracy_score(y_test, boost_pred_3)))

eclf = VotingClassifier(estimators=[('bag', bag_model_2), ('rf', rf_model), ('boost', boost_model_1)], voting='soft')
eclf = eclf.fit(X_train, y_train.ravel())
eclf_pred = eclf.predict(X_test)
print("Ensemble Classification Accuracy: {}".format(accuracy_score(y_test, eclf_pred)))

models = ['bag_model_1', 'bag_model_2', 'bag_model_3', 'rf_model', 'boost_model_1', 'boost_model_2', 'boost_model_3', 'eclf']
accuracy = [accuracy_score(y_test, bag_pred_1), accuracy_score(y_test, bag_pred_2), 
            accuracy_score(y_test, bag_pred_3), accuracy_score(y_test, rf_pred), 
            accuracy_score(y_test, boost_pred_1), accuracy_score(y_test, boost_pred_2), 
            accuracy_score(y_test, boost_pred_3), accuracy_score(y_test, eclf_pred)]

models = pd.Series(models)
accuracy = pd.Series(accuracy)

df = pd.DataFrame({'model': models, 'accuracy': accuracy})

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

fig, ax = plt.subplots(figsize=(15,5))

ax.bar('model', 'accuracy', data=df)
ax.set_title('model comparison')
ax.set_ylabel('accuracy')
ax.set_xlabel('models');